---
title: "AirBnB Hong Kong Analysis"
author: "Tark Auf"
date: '2020-10-19'
draft: no
keywords: "analysis"
image: pic04.jpg
slug: blog8
---


```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width= 7, 
  fig.height=7,
  fig.align = "center"
)
```


```{r load-libraries, warning=FALSE, message=FALSE, echo=TRUE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(GGally)
library(readxl)
library(here)
library(skimr)
library(janitor)
library(broom)
library(tidyquant)
library(infer)
library(openintro)
library(tidyquant)
library(scales)
library(vroom)

```


```{r data_upload, tidy=TRUE, message=FALSE, warning=FALSE}


#loading data
listings <- read_csv("http://data.insideairbnb.com/china/hk/hong-kong/2020-06-15/data/listings.csv")%>% 
    clean_names()

# How many variables/columns? How many rows/observations?
# Which variables are numbers?
# Which are categorical or factor variables (numeric or character variables with variables that have a fixed and known set of possible values?
# What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?

glimpse(listings)

skim(listings) 

```


# Cleaning the data

Here we are selecting the data and specific variables to perform our analysis on. We got rid of qualitative variables, such as description and summary, as transforming qualitative into quantitative data leads to pre-programmed errors, due to the nature of the algorithm.

```{r}

#we never change the real data
hong_kong_listings <- listings %>% 
  select(id, 
         host_id,
         host_since,
         host_is_superhost,
         host_listings_count,
         neighbourhood_cleansed,
         #latitude, does not give extra info as all pretty similiar
         #longitude, does not give extra info as all pretty similiar
         property_type,
         room_type,
         accommodates,
         bathrooms,
         bedrooms,
         beds,
         bed_type,
         #amenities, just one long string
         #square_feet, we noticed that a lot of values are missing so excluded this variable
         price,
         #weekly_price, a lot of NAs
         #monthly_price,a lot of NAs
         security_deposit,
         cleaning_fee,
         guests_included,
         extra_people,
         minimum_nights,
         maximum_nights,
         number_of_reviews,
         reviews_per_month,
         number_of_reviews_ltm,
         review_scores_rating,
         review_scores_accuracy,
         review_scores_cleanliness,
         review_scores_checkin,
         review_scores_communication,
         review_scores_location,
         review_scores_value,
         listing_url,
         city,
         description,
         neighborhood_overview,
         #s_business_travel_ready,
         cancellation_policy) %>% 
#Converting characters to "doubles" and factors where appropriate
  mutate(neighbourhood_cleansed=factor(neighbourhood_cleansed),
         room_type=as.factor(room_type),
         price=parse_number(price),
         security_deposit=parse_number(security_deposit),
         cleaning_fee=parse_number(cleaning_fee),
         extra_people=parse_number(extra_people),
         cancellation_policy=as.factor(cancellation_policy),
         bed_type=as.factor(bed_type),
         city=as.factor(city))

#Inspecting data frame to make sure all the variables are correctly attributed
glimpse(hong_kong_listings) 
skim(hong_kong_listings)
```

Here is a description of some of the key variables in our dataset *hong_kong_listings*:

* `price` = cost per night
* `cleaning_fee`: cleaning fee
* `extra_people`: charge for having more than 1 person
* `property_type`: type of accommodation (House, Apartment, etc.)
* `room_type`:
- Entire home/apt (guests have entire place to themselves)
- Private room (Guests have private room to sleep, all other rooms shared)
- Shared room (Guests sleep in room shared with others)
* `number_of_reviews`: Total number of reviews for the listing
* `review_scores_rating`: Average review score (0 - 100)
* `neighbourhood*`: three variables on a few major neighbourhoods


## Handling missing values
We get rid of NAs by using once again `mutate`, we also filter for min/max nights and accommodates.
We assume for NAs in cleaning fee and security deposits to be 0. Which means, that if we have a NA we now that there is either no cleaning fee or no security deposit. we also think this is then reflected in the daily price.

## Summary of property types

```{r}
Property_type_summary <- hong_kong_listings%>%
  group_by(property_type)%>%
  summarise(count = n())%>%
  mutate(property_proportion = count/sum(count))%>%
  arrange(desc(count))

ggplot(data = Property_type_summary) +
  geom_col(aes(y = count, x = property_type)) +
  coord_flip()

Property_type_top10 <- Property_type_summary%>%
  head(n=10) %>% 
  ggplot() +
  geom_col(aes(y = reorder(property_type, count), x = count), fill = "#00B81F") +
  theme_bw() +
  labs(y = "Property type",
       x = "", 
       title = "The most popular property types on Airbnb \n in Hong Kong")
Property_type_top10

```

The most common four Airbnb property types in Hong Kong are: apartment, condominium, serviced apartment, and hostel, and their proportions out of the total number of listings are: 67.5%, 9.01%, 4.43%, and 3.57%, respectively. 

## Summary of minimum nights

```{r}
Minimum_nights_summary <- hong_kong_listings%>%
  group_by(minimum_nights)%>%
  summarise(count = n())%>%
  mutate(frequency = count/sum(count))

Minimum_nights_top5 <- Minimum_nights_summary%>%
  arrange(desc(count))%>%
  head(n=5) %>% 
  ggplot() +
  geom_col(aes(y = reorder(minimum_nights, count), x = count), fill = "darkorange") +
  theme_bw() +
  labs(y = "Minimum nights",
       x = "", 
       title = "Top 5 minimum nights in Hong Kong")

Minimum_nights_top5
```

The most common values (top 5) of minimum nights are 1, 2, 29, 3, 28 nights respectively. The values that stand out among these common ones are 29 and 28 nights. Since Hong Kong is a metropolis, we think that these two types of Airbnb are intended for people who are in Hong Kong for business purposes rather than tourism. They are in need of a longer-term stay in Hong Kong, so the Airbnb acts like a rented space for them that requires them to stay for at least a month. The benfits of renting an Airbnb for that time is the ease of administration. It is often times impossible to find an apartment for a couple of weeks without going through the administrative hassle of exchanging documents, looking for credit risk and the like.

## Filter and mutate the dataset

Based on the observations and summaries above, we `filter` and `mutate` our dataset in order to obtain only accommodations that are suitable for 2 guests who want to spend 4 nights in the Airbnb. We also `filter` accommodates for the range of <2:9> since we believe that booking a place for up to 9 accommodates by wealthy clients is reasonable. In addition, we create a new variable called `prop_type_simplified` that include the most common 4 property types and the rest are considered as `Other`. We also assume that for each `NA`value in both variables `cleaning_fee`and `security_deposit`, the value is 0, meaning that there is no `cleanin_fee`and no `security_deposit`.

```{r}
#Filter dataset for two guests and 4 nights
#Clean dataset for cleaning_fee, security_deposit, property_type, minimum_nights and accommodates
hong_kong_listings_cleaned <- hong_kong_listings %>%
  mutate(cleaning_fee = case_when(      #considering cleaning_fee as 0 if displayed as NA
    is.na(cleaning_fee) ~ 0, 
    TRUE ~ cleaning_fee),
    security_deposit = case_when(      #considering security_deposit as 0 if displayed as NA
    is.na(security_deposit) ~ 0, 
    TRUE ~ security_deposit),
    prop_type_simplified = case_when(   #regrouping of property_types: put all less popular property types into "Other"
    property_type %in% c("Apartment",
                         "Hostel",
                         "Condominium",
                         "Serviced apartment")~ property_type , 
    TRUE ~ "Other"),
    prop_type_simplified=as.factor(prop_type_simplified)) %>% #creating factors
  filter(minimum_nights<=4, maximum_nights>=4, accommodates>=2 , accommodates<=9) #filtering dataframe

#Visually inspecting cleaned data set
glimpse(hong_kong_listings_cleaned)
skim(hong_kong_listings_cleaned)

```

## Calculate total price for 4 nights and data transformation

To end the pre-processing section, we calculated `price_4_nights` as our target variable for regression. It is the total price of 4 nights and two people for each listing. 
In addition, because some of the total `price_4_nights` is equal to 0, `log(price_4_nights)` would turn out to be negative infinity that hinders further analysis. Therefore, we transformed those `price_4_nights` that are equal to 0 by adding 1 while keeping others unchanged. Since log(1) is still 0, it does not affect our regression outcome.

```{r}
hong_kong_listings_total_price<-hong_kong_listings_cleaned %>%
  # price_4_nights calculation
  mutate(price_4_nights=price*4+
           cleaning_fee+
           if_else(guests_included==1, extra_people*4,0),
         # Add 1 to price_4_nights that are equal to 0
         price_4_nights_transformed = price_4_nights +
           if_else(price_4_nights==0, 1,0),
         log_price_4_nights = log(price_4_nights),
         log_price_4_nights_transformed = log(price_4_nights_transformed))
```

## New variables: `neighbourhood_simplified` and `rating_group`

Using city knowledge, we create a new categorical variable `neighbourhood_simplified` where we group neighbourhoods together geographically into 5 different zones. We also create a new categorical variable, `rating_group`, to divide the properties into 3 categories; properties with `review_scores_rating` less than 90, greater than 90 and No Rating.

```{r}

hong_kong_listings_neighbourhood_simplified <- hong_kong_listings_total_price %>% 
  mutate(
neighbourhood_simplified = case_when(
      neighbourhood_cleansed=="Central & Western"~"zone_1",
      neighbourhood_cleansed=="Eastern"~"zone_1",
      neighbourhood_cleansed=="Islands"~"zone_2",
      neighbourhood_cleansed=="Kowloon City"~"zone_3",
      neighbourhood_cleansed=="Kwai Tsing"~"zone_4",
      neighbourhood_cleansed=="Kwun Tong"~"zone_3",
      neighbourhood_cleansed=="North"~"zone_4",
      neighbourhood_cleansed=="Sai Kung"~"zone_5",
      neighbourhood_cleansed=="Sha Tin"~"zone_4",
      neighbourhood_cleansed=="Sham Shui Po"~"zone_3",
      neighbourhood_cleansed=="Southern"~"zone_1",
      neighbourhood_cleansed=="Tai Po"~"zone_4",
      neighbourhood_cleansed=="Tsuen Wan"~"zone_4",
      neighbourhood_cleansed=="Tuen Mun"~"zone_4",
      neighbourhood_cleansed=="Wan Chai"~"zone_1",
      neighbourhood_cleansed=="Wong Tai Sin"~"zone_3",
      neighbourhood_cleansed=="Yau Tsim Mong"~"zone_3",
      neighbourhood_cleansed=="Yuen Long"~"zone_4"),
rating_group= case_when(
  review_scores_rating <90 ~ "Under 90",
  is.na(review_scores_rating)~"No Rating",
  TRUE ~ "Over 90"))

skim(hong_kong_listings_neighbourhood_simplified)
```

## Overview of our cleansed data

### How many variables *(coloumns)*? How many observations *(rows)*?

The original dataset, `listings`, had 11187 observations with 106 variables. After cleaning the data, removing variables and observations with a lot of NAs, and using our own judgement to remove insignificant variables, we end up with a final dataset, `hong_kong_listings_neighbourhood_simplified`, with 6437 observations and 42 variables. This dataset is used for our regression models.

### Which variables are numbers?

The original dataset, `listings`, had 39 numeric variables whereas our final cleaned dataset had 28 numeric variables. Some examples of numeric variables in the dataset are the variables `id`, `accomodates`, `bedrooms`, `beds`, `price`, `price_4_nights` etc.

### Which are categorical or factor variables? - *numeric or character variables with variables that have a fixed and known set of possible values?*
The original dataset, `listings`, had 46 categorical or factor variables whereas our final cleaned dataset had 12 categorical and factor variables. Some examples of factor and categorical variables in the dataset are the variables `neighbourhood_cleansed`, `room_type`, `bed_type`.

# Exploratory Data Analysis

## Summary statistics and favstats

Now that we have cleaned our data sets for our specific target (4 nights, 2 people) we will conduct a exploratory data analysis. 

```{r}
#summary to check for NA's and general statistics
summary(hong_kong_listings_neighbourhood_simplified)

#running favstats on some interesting variable combinations
favstats(price_4_nights_transformed~accommodates,
         data=hong_kong_listings_neighbourhood_simplified) 

favstats(price_4_nights_transformed~neighbourhood_cleansed,
         data=hong_kong_listings_neighbourhood_simplified)

favstats(price_4_nights_transformed~host_is_superhost,
         data=hong_kong_listings_neighbourhood_simplified)

favstats(price_4_nights_transformed~prop_type_simplified,
         data=hong_kong_listings_neighbourhood_simplified)

favstats(price_4_nights_transformed~minimum_nights,
         data=hong_kong_listings_neighbourhood_simplified)
```


## Data visualization

Building upon the above summary and favstats investigations, we visualize our data by using ggplot2.

```{r warning=FALSE}

#Distribution of Airbnb property types in Hong Kong 
ggplot(hong_kong_listings_neighbourhood_simplified, 
       aes(y=(prop_type_simplified),
           fill = neighbourhood_simplified))+
  geom_bar()+
  facet_wrap(~neighbourhood_simplified)+
  labs(title = "Distribution of Airbnb Property Types \n in Different Geographic Zones ",
       x = "Property type",
       y = "Number of Properties") +   
  theme_bw() +
  theme(title = element_text(size = 15, face = "bold"),
        axis.text.x = element_text(size = 10, angle=30),
        axis.text.y = element_text(size = 10), legend.position = "none")

# Density plot of ratings by zones
ggplot(hong_kong_listings_neighbourhood_simplified, aes(x=review_scores_rating, fill=neighbourhood_simplified, alpha = 0.1))+
  geom_density()+
  scale_alpha(guide = "none") +
  labs(title = "Density plot of ratings by Different \n Geographic Zones",
       x = "Ratings",
       y = "Density") +  theme_bw()+

  theme(title = element_text(size = 15, face = "bold"),
        axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 8),
        legend.text = element_text(size=8),
        legend.position = "bottom")   

# Distribution of average cleaning fee and security deposit by property type
cleaning_security <- hong_kong_listings_neighbourhood_simplified %>%
  group_by(prop_type_simplified) %>%
  summarise(mean_cleaning_fee = mean(cleaning_fee),
            mean_security_deposit = mean(security_deposit))

cleaning_security <- pivot_longer(cleaning_security,
                                  cols = 2:3, names_to = "Type", values_to = "value")

ggplot(cleaning_security,aes(x=prop_type_simplified, y = value, fill = Type))+
  geom_col(position = "dodge")+
  labs(title = "Distribution of Average Cleaning Fee and \n Security Deposit by Property Type",
       x = "Property Type",
       y = "Dollars") +
  theme_bw()+
  theme(title = element_text(size = 15, face = "bold"),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        legend.text = element_text(size=10))

# Boxplot of log(prices_4_night) by zones
ggplot(hong_kong_listings_neighbourhood_simplified,
       aes(x=neighbourhood_simplified, y = log_price_4_nights_transformed,
           fill = neighbourhood_simplified, alpha =0.5))+
  geom_boxplot()+  
  labs(title = "Boxplot of Total Price for 4 nights \n by zones",
       subtitle = "Zone 3 has the lowest median total price",
       x = "Zones",
       y = "Log (Price for 4 Nights)") +  
  theme_bw()+

  theme(title = element_text(size = 15, face = "bold"),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        legend.position = "none")


```

## Correlation matrix

```{r, message=FALSE, warning=FALSE}
#Producing scatterplot-correlation matrix between important variables in the dataset
ggp <- hong_kong_listings_neighbourhood_simplified %>% 
      select(c(price_4_nights, 
               neighbourhood_simplified, 
               accommodates, 
               bathrooms, 
               beds, 
               security_deposit, 
               cleaning_fee, 
               number_of_reviews, 
               review_scores_rating)) %>% 
  ggpairs(cardinality_threshold = NULL)

print(ggp, progress = F)

```

### What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?

Above, we check the correlations between the numeric variables in the dataset. Intuitively, we see that the variables Price_4_Nights and Price are highly correlated at 0.997 since Price_4_nights is calculated from Price. We also see that the variables accommodates and beds have a very strong relationship, with correlation equal to 0.758. The variables reviews_per_month and number_of_reviews_ltm are also highly correlated at 0.826. Furthermore, we see that the variable review_scores_rating have very strong relationships with each of the other rating categories such as review_scores_accuracy and review_scores_cleanliness etc with a correlation coefficients greater than 0.7. This would be particularly useful when we select variables for our regression analysis as we know that using the variable review_scores_rating would suffice.

# Mapping
```{r}
library(leaflet)
leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)

```

# Regression Analysis

## Price_4_nights vs. Log (price_4_nights)

```{r}
# histogram of price_4_nights
ggplot(hong_kong_listings_total_price, aes (x = price_4_nights))+
  geom_histogram()+
  xlim(c(0,20000))+
  labs(title = "Histogram of Total Prices for 4 Nights",
       x = "Total Prices for 4 Nights",
       y = "Count")+
  theme(title = element_text(size=15),
          axis.text.x = element_text(size=10),
        axis.text.y=element_text(size=10))+
  theme_bw()

# histogram of log(price_4_nights)
ggplot(hong_kong_listings_total_price, aes (x = log_price_4_nights))+
  geom_histogram()+
  labs(title = "Histogram of Log (Prices for 4 Nights)",
       x = "Log Prices for 4 Nights",
       y = "Count")+
  theme(title = element_text(size=15),
          axis.text.x = element_text(size=10),
        axis.text.y=element_text(size=10))+
  theme_bw()

```

We should use log(price_4_nights) because we can see from the histograms that the log(price_4_nights) distribution has a roughly normal shape, while the distribution of total price_4_nights is right-skewed. If we use the total price_4_nights in the regression analysis, the regression line might not be linear and variance might not be constant.

## Model 1

```{r}
# explanatory variables: prop_type_simplified, number_of_reviews, review_scores_rating
model1 <- lm(log_price_4_nights_transformed ~ 
               prop_type_simplified + 
               number_of_reviews + 
               review_scores_rating, 
             data = hong_kong_listings_total_price)
msummary(model1)
car::vif(model1)
plot(model1)
```

### Interpretations of Regression Output

Since we transformed the dependent variable by taking the logarithm of `price_4_nights`, we need to exponentiate the coefficients, then subtract the number by 1 to arrive at the unit increase in Y variable by increasing one unit of X variable. Property type is also a categorical variable, so when performing regression analysis we have `Apartment` has our baseline, which is not shown in the regression output report.<br/>

The coefficient for `number_of_reviews` is -0.000868, so the unit increase in `price_4_nights` will be (e^-0.000868 -1). That is, for every increase of 1 in the review rating score, the `price_4_nights` will decrease by 0.000868. <br/>

The coefficient for `review_scores_rating` is 0.007045, so the unit increase in `price_4_nights` will be (e^0.007043 -1). That is, for every increase of 1 in the review rating score, the `price_4_nights` will increase by 0.00707. <br/>

* if the property type is `condominium`, everything else equal, `price_4_nights` will increase by (e^-0.142477 -1 ) = -0.133, or decrease by 0.133 compared to property type being apartment.<br/>
if the property type is `hostel`, everything else equal, `price_4_nights` will increase by (e^-0.449322 -1) = -0.362, or decrease by 0.362 compared to property type being apartment.

* if the property type is `other`, everything else equal, `price_4_nights` will increase by (e^-0.173379 -1 ) = -0.159, or decrease by 0.159 compared to property type being apartment.<br/>
if the property type is serviced apartment, everything else equal, price_4_nights will increase by (e^-0.172016 -1) = -0.158, or decrease by 0.158 compared to property type being apartment.

### Interpretation of the above plots

* first plot (Fitted vs Residual):
  + detects several types of violations in the linear regression assumptions
    + Does linearity hold? This is indicated by the mean residual value for every fitted value region being close to 0. The closer ther red line is to the dashed line
    + Whether homoskedasticity holds. The spread of residuals should be approximately the same across the x-axis.
    + Whether there are outliers. This is indicated by some ‘extreme’ residuals that are far from the rest.
    
* In the second plot (Normal Q-Q Plot): 
  + The Q-Q plot, or quantile-quantile plot, is a graphical tool to help us assess if a set of data plausibly came from some theoretical distribution such as a Normal or exponential.
    + A Q-Q plot is a scatterplot created by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, we should see the points forming a line that’s roughly straight
    
* In the third plot (Scale Location):
  + red line is approximately horizontal. Then the average magnitude of the standardized residuals isn’t changing much as a function of the fitted values.
  + spread around the red line doesn’t vary with the fitted values. Then the variability of magnitudes doesn’t vary much as a function of the fitted values.
  
* Fourth plot (Residuals vs Leverage):
  + This can help detect outliers in a linear regression mode:
    + We’re looking at how the spread of standardized residuals changes as the leverage, or sensitivity of the fitted \hat{y}_i to a change in y_i, increases. Firstly, this can also be used to detect heteroskedasticity and non-linearity. The spread of standardized residuals shouldn’t change as a function of leverage: here it appears to decrease, indicating heteroskedasticity.
    + Second, points with high leverage may be influential: that is, deleting them would change the model a lot. For this we can look at Cook’s distance, which measures the effect of deleting a point on the combined parameter vector. Cook’s distance is the dotted red line here, and points outside the dotted line have high influence. In this case there are no points outside the dotted line


## Model 2

```{r}
# explanatory variables in model1 plus room_type
model2 <- lm(log_price_4_nights_transformed ~ 
               prop_type_simplified + 
               number_of_reviews + 
               review_scores_rating + 
               room_type, 
             data = hong_kong_listings_total_price)

msummary(model2)
car::vif(model2)
plot(model2)
```

`room_type` is a significant indicator of `price_4_nights`, because as shown in the summary statistics below, the t-values for three different room types all have absolute values greater than 2.

# Further Regression Analysis

## Model 3

When performing regression analysis, we removed variables that have perfect collinearity with others (`property type` and `property_type_simplified`). In addition, after checking for Variance Inflation Factors, we found out that `neighbourhood_cleansed` and `city` have very high collinearity, so we also removed both variables from our regression analysis and used `neighbourhood_simplified` instead. Although the VIF of `reviews_per_month`, `room_type` and `review_scores_rating` are all larger than 5 but smaller than 10, we still decided to keep these variables for our next model because they could be influential on our total price.

```{r}

model3 <- lm(log_price_4_nights_transformed ~ . 
             -log_price_4_nights 
             - price_4_nights 
             - price_4_nights_transformed 
             - listing_url 
             - id 
             - host_id 
             - description 
             - neighborhood_overview 
             - city 
             - property_type 
             - neighbourhood_cleansed,
             data = hong_kong_listings_neighbourhood_simplified)
msummary(model3)
car::vif(model3)
plot(model3)

```

## Model 4

For our model 4, we further removed variables that have t-values less than 2 (`host_since`,`bathrooms`, `bedrooms`, `beds`, `bed_type`, `maximum_nights`, `number_of_reviews_ltm`,`number_of_reviews`, `review_scores_accuracy`, `review_scores_location`, `cancellation_policy` and `rating_group`) to refine our model.

```{r}
model4 <- lm(log_price_4_nights_transformed ~ 
               host_is_superhost +  
               host_listings_count + 
               room_type +
               accommodates + 
               price + 
               security_deposit + 
               cleaning_fee + 
               guests_included + 
               extra_people + 
               minimum_nights +
               review_scores_rating +
               review_scores_cleanliness + 
               review_scores_checkin +
               review_scores_communication +
               review_scores_value + 
               prop_type_simplified + 
               neighbourhood_simplified+
               rating_group,
             data = hong_kong_listings_neighbourhood_simplified)

msummary(model4)
car::vif(model4)
plot(model4)

```

## Model 5
For our model 5, we further removed variables from model 4 that are insignificant (have t-values less than 2). They are: `review_scores_checkin` and `review_scores_communication`.
```{r}
model5 <- lm(log_price_4_nights_transformed ~
               host_is_superhost +  
               host_listings_count + 
               accommodates + 
               price + 
               security_deposit + 
               cleaning_fee + 
               guests_included +
               extra_people +
               minimum_nights + 
               number_of_reviews + 
               review_scores_rating +
               review_scores_cleanliness + 
               review_scores_value + 
               prop_type_simplified + 
               neighbourhood_simplified+
               rating_group,
             data = hong_kong_listings_neighbourhood_simplified)

msummary(model5)
car::vif(model5)
plot(model5)
```

## Model 6

Lastly, we removed one more variable `guests_included` that has t-value less than 2 in model 5. Model 6 is our final regression model, as all the variables in the model are significant.

```{r}
model6 <- lm(log_price_4_nights_transformed ~  
               host_is_superhost +  
               host_listings_count + 
               accommodates + 
               price + 
               security_deposit + 
               cleaning_fee + 
               extra_people +
               minimum_nights + 
               number_of_reviews + 
               review_scores_rating +
               review_scores_cleanliness + 
               review_scores_value + 
               prop_type_simplified +
               neighbourhood_simplified,
             data = hong_kong_listings_neighbourhood_simplified)

msummary(model6)
car::vif(model6)
plot(model6)
```

# Models Overview

```{r}

huxtable::huxreg(model1,
                 model2,
                 model3,
                 model4,
                 model5,
                 model6)

```

## Interpretations based on these models

### Bathroom, bedroom, beds and accomodates

Bathroom, bedroom and number of beds are insignificant explanatory factors for the price of an airbnb for 4 nights, because their corresponding t-values are less than 1.96, as shown in model 3. Therefore, we removed these three variables in the following models. However, the size of the Airbnb (accommodates) does has explanatory power in predicting the total price for 4 nights.


Hence, the model 6, which is model 5 plus bedrooms is our strongest model so far. It can explain around 58% of the deviation of prices by the included variables. The strongest price driver is by no surprise the number of accommodates in the airbnb and being a superhost. This does not come out of the blue, because we all know from own experience that prices per night for a hotel room are often per person prices, hence the price of a room will increase if there is an extra person living in that room. 


### Superhost

Based on our final regression model (model6), we can see that after controlling for other variables, Superhosts do command a pricing premium, because it is a significant variable in the model and has a coefficient of 0.101 when regressing against `log(price_4_nights)`. Therefore, the fact that the host is a superhost increases the price_4_nights by (e^0.101-1) = 0.106 compared to the host not being a superhost. This makes economic sense, because being a superhost is very similar to a brand name and strong brands typically have higher pricing power.


### Cancellation Policy

In our model 3, we see that cancellation policy is not a significant explanatory variable because all the different values of cancellation policy have t-values less than 1.96. To again test for its significance, we tried to include `cancellation policy` in our final model and see what happens. However, adding the variable is neither significant nor adds any explanatory power to our model. So we come to the conclusion that it is best to remove this variable from our model. It is better to have a less "complex" model with the same explanatory model as the complex.

### Number of host listings
Since our Hong Kong dataset does not include information regarding whether the hosts advertise the exact locations of their listings, we choose to explore the relationship between the number of host listings and the `price_4_nights`. From our model 6, the coefficient for `host_listings_count` is -0.00225 when regressing against `log(price_4_nights)`. Therefore, for every increase in host listings, the price_4_nights decreases by 0.00225. This might be the case because as a host owns more listings, he/she cares less about pricing of each individual listing, which leads to a slight price decrease.

#Prediction for price_4_nights in Hong Kong

```{r}

#Filtering for properties that satisfy the conditions, have a private room, at least 10 reviews and an average rating over 90
hong_kong_listings_predict <- hong_kong_listings_neighbourhood_simplified %>% 
#Since all room_types besides shared room have private rooms, we only have to filter out room types that are shared rooms 
  filter(room_type != "Shared room", number_of_reviews >= 10, rating_group == "Over 90")


#log prediction + transformation
prediction <- exp(predict(model6, newdata= hong_kong_listings_predict, interval = "confidence"))
prediction %>% 
  summary()

plot(model6$residuals)


#non log
# here we look at the model without the log -> small differences
model_predict <- lm(price_4_nights ~  
               host_is_superhost +  
               host_listings_count + 
               accommodates + 
               price + 
               security_deposit + 
               cleaning_fee + 
               extra_people +
               minimum_nights + 
               number_of_reviews + 
               review_scores_rating +
               review_scores_cleanliness + 
               review_scores_value + 
               prop_type_simplified +
               neighbourhood_simplified,
             data = hong_kong_listings_predict)

confint(model_predict, level = 0.95)


predict(model_predict, newdata = hong_kong_listings_predict, interval = "confidence") %>% 
  summary()


plot(model_predict$residuals)
```



``` {r}
#Bootstrapping
set.seed(1234)

boot_predict <- hong_kong_listings_predict %>%

  # Specify the variable of interest
  specify(response = log_price_4_nights_transformed) %>%
  
  # Generate a bunch of bootstrap samples
  generate(reps = 1000, type = "bootstrap") %>%
  
  # Find the median of each sample
  calculate(stat = "mean")

percentile_ci <- boot_predict %>%
  get_ci(level = 0.95, type = "percentile")

ggplot(boot_predict, aes(x = stat)) +
  geom_histogram() +
  labs(title= "Bootstrap distribution",
       x = "Median delta per bootstrap sample",
       y = "Count") +
  geom_vline(xintercept = percentile_ci$lower_ci, colour = 'orange', size = 2, linetype = 2) +
  geom_vline(xintercept = percentile_ci$upper_ci, colour = 'orange', size = 2, linetype = 2)

visualize(boot_predict) + 
  shade_ci(endpoints = percentile_ci,fill = "khaki")+
  geom_vline(xintercept = percentile_ci$lower_ci, colour = "red")+
  geom_vline(xintercept = percentile_ci$upper_ci, colour = "red")

```

# Conclusion

## Model effectiveness and limitations
Our final regression model (model6) includes the following 13 explanatory variables:

* host_is_superhost
* host_listings_count
* accommodates
* price
* security_deposit
* cleaning_fee
* extra_people
* minimum_nights 
* number_of_reviews
* review_scores_cleanliness 
* review_scores_value 
* prop_type_simplified
* neighbourhood_simplified

This model has an adjusted R-Squared of 0.579, meaning that we were able to explain 58% of the variability of price_4_nights using the above variables. However, it is worth noticing that our adjusted R-Squared decreases from 0.709 in model 3 as we removed the insignificant variables. This is probably due to the fact that as we add more variables to a model, the ability to account for the variations increase. However, an efficient regression model should only contain variables that are significant and should not be highly complex. Therefore, we believe that our final model is a strong one based on the current dataset. <br/>
However, there are much more factors that could affect `price_4_nights` that is not reflected in this dataset and analysis. For example, there are macroeconomic factors that can impact the pricing of Airbnb listings, especially under unusual circumstances that could limit travel conditions like now. In addition, total prices could vary greatly among different seasons due to holidays and vacations. We should also take into account the effect of pricing by competitors like Booking.com and Expedia. These are all variables that are not incorporated in the model and are worth exploring in future analysis.


# Take Aways

This exercise has allowed us to apply all our knowledge in R and beyond. We were able to incorporate our statistical knowledge that we gathered through this course to a real life problem. We learned how to use real data to read our surroundings and take action accordingly. If we are traveling on a budget (as most student usually do) we know what variables or in this case qualities we need to remove from our filter to find the cheapest accommodation for our budget. 

We want to thank Prof. Kostis and his army of TAs that were always supportive in this new environment (We are not only talking about COVID here ;))
